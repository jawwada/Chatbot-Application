{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#    Hyperparameter Tuning for Intent Classification using LSTM with Attention Mechanism\n",
    "This notebook is 2nd part of the Ultimate AI Challenge. In the previous notebook, I trained a LSTM Model with Attention Mechanism for Intent Classification on the ATIS dataset. In this notebook, I perform a hyper parameter optimization to learn the best parameters for the model and also log our experiments using an ML server, e.g. MLFlow. Propreitary clouds already use experiment logging, model registry and deployment services, e.g. Vertex AI in GCP, Azure ML and Amazon Sagemaker. I have worked in Vertex AI and Azure ML. MLflow + Optuna is a good open source and scalable alternative to them. I use Optuna for hyperparameter tuning and MLflow for experiment tracking and model registry. Model Serving is done through pytorch save and load methods. To avoid pickling and version issues, one can also use model state dictionaries. The notebook is divided into the following sections:\n",
    "1. Data Preparation\n",
    "2. Hyperparameter Tuning\n",
    "3. Model Training and Evaluation\n",
    "4. Visualize the results\n",
    "5. Model Export, Registry, Model Loading and Inference\n",
    "\n",
    "Let's start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T17:00:41.055790Z",
     "start_time": "2023-11-23T17:00:34.092485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.nn as nn\n",
    "from machine_learning.IntentClassifierLSTMWithAttention import IntentClassifierLSTMWithAttention\n",
    "from machine_learning.IntentTokenizer import IntentTokenizer\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from machine_learning.model_utils import train, evaluate, predict, get_or_create_experiment\n",
    "import optuna\n",
    "import logging\n",
    "import mlflow\n",
    "from optuna.visualization import plot_optimization_history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Data Preparation\n",
    "Steps:\n",
    "1. Load the data\n",
    "2. Tokenize the data\n",
    "3. Create a PyTorch Dataset\n",
    "4. Create a PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T17:03:18.946528Z",
     "start_time": "2023-11-23T17:03:18.934354Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside IntentTokenizer\n",
      "Actual Vocabulary Size: 890\n",
      "Encoding labels for the first time and adding unknown class.\n",
      "Label Encoding: {'abbreviation': 0, 'aircraft': 1, 'aircraft+flight+flight_no': 2, 'airfare': 3, 'airfare+flight_time': 4, 'airline': 5, 'airline+flight_no': 6, 'airport': 7, 'capacity': 8, 'cheapest': 9, 'city': 10, 'distance': 11, 'flight': 12, 'flight+airfare': 13, 'flight_no': 14, 'flight_time': 15, 'ground_fare': 16, 'ground_service': 17, 'ground_service+ground_fare': 18, 'meal': 19, 'quantity': 20, 'restriction': 21, '<unknown>': 22}\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
    "\n",
    "train_df = pd.read_csv('data/atis/train.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "test_df = pd.read_csv('data/atis/test.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "tokenizer = IntentTokenizer(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T17:02:13.698118Z",
     "start_time": "2023-11-23T17:02:13.669268Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: torch.Size([4634, 46])\n",
      "Number of training batches: 145\n",
      "Number of test samples: torch.Size([850, 30])\n",
      "Number of test batches: 27\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# define constants and hyperparameters\n",
    "vocab_size=tokenizer.max_vocab_size\n",
    "output_dim=len(tokenizer.le.classes_)\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "\n",
    "train_data = tokenizer.process_data(train_df, device=device)\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "print(\"Number of training samples:\", train_data.tensors[0].size())\n",
    "print(\"Number of training batches:\", len(train_loader))\n",
    "\n",
    "test_data = tokenizer.process_data(test_df, device=device)\n",
    "print(\"Number of test samples:\", test_data.tensors[0].size())\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "print(\"Number of test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Hyperparameter Tuning\n",
    "The Model I am using for the hyperparameter tuning is the IntentClassifierLSTMWithAttention. The hyperparameters are:\n",
    "1. Learning rate : 1e-3 to 1e-1\n",
    "2. Hidden dimension : 32, 64, 128, 256\n",
    "3. Embedding dimension : 64, 128, 256, 512\n",
    "4. Dropout rate : 0.1 to 0.5\n",
    "5. Weight decay : 1e-6 to 1e-3\n",
    "\n",
    "The objective function is the average validation accuracy over 5 folds. The best model is the one with the highest average validation accuracy. Note our test data is completely hidden to the accuracy optimizer of optuna. One can choose any metric to optimize, for example minimization of loss, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def log_hyperparameters(trial):\n",
    "    # Log hyperparameters\n",
    "    \n",
    "    mlflow.log_param(\"lr\", trial.params[\"lr\"])\n",
    "    mlflow.log_param(\"hidden_dim\", trial.params[\"hidden_dim\"])\n",
    "    mlflow.log_param(\"embedding_dim\", trial.params[\"embedding_dim\"])\n",
    "    mlflow.log_param(\"dropout_rate\", trial.params[\"dropout_rate\"])\n",
    "    mlflow.log_param(\"weight_decay\", trial.params[\"weight_decay\"])\n",
    "    print(f'lr: {trial.params[\"lr\"]}, hidden_dim: {trial.params[\"hidden_dim\"]}, embedding_dim: {trial.params[\"embedding_dim\"]}, dropout_rate: {trial.params[\"dropout_rate\"]}, weight_decay: {trial.params[\"weight_decay\"]}')\n",
    "\n",
    "    return\n",
    "\n",
    "def log_metrics(trial, accuracy):\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    return\n",
    "def objective(trial):\n",
    "    with mlflow.start_run():\n",
    "        # Suggest hyperparameters\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [32, 64, 256])\n",
    "        embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        log_hyperparameters(trial)\n",
    "        # Model, loss, and optimizer\n",
    "        # model = IntentClassifierLSTM(cfg.vocab_size, embedding_dim, hidden_dim, cfg.output_dim,dropout_rate).to(device)\n",
    "        model = IntentClassifierLSTMWithAttention(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_val_acc = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(train_df)):\n",
    "            # Prepare fold data\n",
    "            train_data_subset = tokenizer.process_data(train_df.loc[train_idx,:], device=device)\n",
    "            val_data_subset = tokenizer.process_data(train_df.loc[val_idx,:], device=device)\n",
    "            train_subset_loader = DataLoader(train_data_subset, batch_size=batch_size, shuffle=True)\n",
    "            val_subset_loader = DataLoader(val_data_subset, batch_size=batch_size, shuffle=False)\n",
    "            fold_loss = train(model, optimizer, criterion, train_subset_loader, num_epochs)\n",
    "            val_accuracy = evaluate(model,  criterion, val_subset_loader, data_type=\"Validation\")\n",
    "            print(f'Fold: {fold + 1}, Training Loss: {fold_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "            fold_val_acc.append(val_accuracy)\n",
    "        average_val_acc = sum(fold_val_acc) / len(fold_val_acc)\n",
    "        print(f'Average validation accuracy: {average_val_acc:.4f}')\n",
    "        log_metrics(trial, average_val_acc)\n",
    "    return average_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Optuna Study for Hyperparameter Optimization\n",
    "Create an experiment in MLflow and run the hyperparameter tuning experiment. The best model is the one with the highest average validation accuracy. You can install the mlflow and optuna using pip install. To start mlflow server, I used the following command\n",
    "`mlflow server --backend-store-uri=sqlite:///mlrunsdb15.db --default-artifact-root=file:mlruns --host 127.0.0.1 --port 1234`\n",
    "Once started, it creates mlruns directory in project root and also a db in the root to log the progress, store models and experiments. In practise, it is installed on a server, and http requests are sent to the server. Anyhow pay close attention to the directory you give in the command to run the server. Here I keep it simple. Optuna also creates a db to store it's studies. Here I choose 20 tries. For 5 folds cross validation, and 5 epochs each, the study takes less than an hour my M1 machine. Optuna uses Bayesian Parameter Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the MLflow Server\n",
    "\n",
    "pip install mlflow\n",
    "\n",
    "`mlflow server --backend-store-uri=sqlite:///mlrunsdb15.db --default-artifact-root=file:mlruns --host 127.0.0.1 --port 1234`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T17:00:45.585347Z",
     "start_time": "2023-11-23T17:00:45.547671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Run with id=6b7f7b7cf0194e4f945873b14bca927a not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     25\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mlog_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Model, loss, and optimizer\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# model = IntentClassifierLSTM(cfg.vocab_size, embedding_dim, hidden_dim, cfg.output_dim,dropout_rate).to(device)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m, in \u001b[0;36mlog_hyperparameters\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_hyperparameters\u001b[39m(trial):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Log hyperparameters\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m, trial\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/fluent.py:644\u001b[0m, in \u001b[0;36mlog_param\u001b[0;34m(key, value, synchronous)\u001b[0m\n\u001b[1;32m    643\u001b[0m run_id \u001b[38;5;241m=\u001b[39m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/client.py:834\u001b[0m, in \u001b[0;36mMlflowClient.log_param\u001b[0;34m(self, run_id, key, value, synchronous)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:330\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value, synchronous)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:321\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_param\u001b[0;34m(self, run_id, key, value, synchronous)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:210\u001b[0m, in \u001b[0;36mRestStore.log_param\u001b[0;34m(self, run_id, param)\u001b[0m\n\u001b[1;32m    207\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m    208\u001b[0m     LogParam(run_uuid\u001b[38;5;241m=\u001b[39mrun_id, run_id\u001b[38;5;241m=\u001b[39mrun_id, key\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mkey, value\u001b[38;5;241m=\u001b[39mparam\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[1;32m    209\u001b[0m )\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLogParam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     58\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:210\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    209\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 210\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:142\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_DOES_NOT_EXIST: Run with id=6b7f7b7cf0194e4f945873b14bca927a not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m storage_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_class_name)\n\u001b[1;32m     12\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39mmodel_class_name, load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, storage\u001b[38;5;241m=\u001b[39mstorage_name,direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     44\u001b[0m     average_val_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(fold_val_acc) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(fold_val_acc)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_val_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     log_metrics(trial, average_val_acc)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m average_val_acc\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/fluent.py:190\u001b[0m, in \u001b[0;36mActiveRun.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[1;32m    189\u001b[0m     status \u001b[38;5;241m=\u001b[39m RunStatus\u001b[38;5;241m.\u001b[39mFINISHED \u001b[38;5;28;01mif\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m RunStatus\u001b[38;5;241m.\u001b[39mFAILED\n\u001b[0;32m--> 190\u001b[0m     \u001b[43mend_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunStatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/fluent.py:446\u001b[0m, in \u001b[0;36mend_run\u001b[0;34m(status)\u001b[0m\n\u001b[1;32m    444\u001b[0m run \u001b[38;5;241m=\u001b[39m _active_run_stack\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    445\u001b[0m _last_active_run_id \u001b[38;5;241m=\u001b[39m run\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m--> 446\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_last_active_run_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _last_active_run_id \u001b[38;5;129;01min\u001b[39;00m run_id_to_system_metrics_monitor:\n\u001b[1;32m    448\u001b[0m     system_metrics_monitor \u001b[38;5;241m=\u001b[39m run_id_to_system_metrics_monitor\u001b[38;5;241m.\u001b[39mpop(_last_active_run_id)\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/client.py:1909\u001b[0m, in \u001b[0;36mMlflowClient.set_terminated\u001b[0;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_terminated\u001b[39m(\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, status: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, end_time: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Set a run's status to terminated.\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \n\u001b[1;32m   1869\u001b[0m \u001b[38;5;124;03m    :param status: A string value of :py:class:`mlflow.entities.RunStatus`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1907\u001b[0m \u001b[38;5;124;03m        status: KILLED\u001b[39;00m\n\u001b[1;32m   1908\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1909\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_terminated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:575\u001b[0m, in \u001b[0;36mTrackingServiceClient.set_terminated\u001b[0;34m(self, run_id, status, end_time)\u001b[0m\n\u001b[1;32m    573\u001b[0m end_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;28;01mif\u001b[39;00m end_time \u001b[38;5;28;01melse\u001b[39;00m get_current_time_millis()\n\u001b[1;32m    574\u001b[0m status \u001b[38;5;241m=\u001b[39m status \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;28;01melse\u001b[39;00m RunStatus\u001b[38;5;241m.\u001b[39mto_string(RunStatus\u001b[38;5;241m.\u001b[39mFINISHED)\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_run_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_status\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRunStatus\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:151\u001b[0m, in \u001b[0;36mRestStore.update_run_info\u001b[0;34m(self, run_id, run_status, end_time, run_name)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Updates the metadata of the specified run.\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m    143\u001b[0m     UpdateRun(\n\u001b[1;32m    144\u001b[0m         run_uuid\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     )\n\u001b[1;32m    150\u001b[0m )\n\u001b[0;32m--> 151\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mUpdateRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RunInfo\u001b[38;5;241m.\u001b[39mfrom_proto(response_proto\u001b[38;5;241m.\u001b[39mrun_info)\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     57\u001b[0m endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     58\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:210\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    208\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m    209\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 210\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    212\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:142\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_DOES_NOT_EXIST: Run with id=6b7f7b7cf0194e4f945873b14bca927a not found"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:1234')\n",
    "\n",
    "model_class_name = \"IntentClassifierLSTMWithAttention\"\n",
    "#optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "storage_name = \"sqlite:///{}.db\".format(model_class_name)\n",
    "study = optuna.create_study(study_name=model_class_name, load_if_exists=True, storage=storage_name,direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "best_trial = study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Best Model Training and Evaluation (Saving, Reloading the best model, through optuna or mlflow)\n",
    "Once I find the best set of hyper parameters, you can open mlflow on tracking uri, e.g. in my case , I set http://127.0.0.1:1234. Also if you install optuna-dashboard, you can see very nice visualizations and get very detailed insights on hyperparameter space, their importance, and why some combinations work more than others. I invite to try it. Tune the best model with a larger number of epochs and evaluate it on the test set. You can reload an optuna study from its' db later to get the best parameters and train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Train the best model\n",
    "Let's say that you have saved an optuna study and you want to reload it later. You feel that the number of epochs were not enough and you want to train the best model with more epochs. Or you want save the model initialization parameters so that you can load the model initial state later and use it along with the saved state dictionary. You can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:58:40.222221Z",
     "start_time": "2023-11-23T16:58:39.808658Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import logging\n",
    "import sys\n",
    "# Reload Optuna Study to get the best parameters\n",
    "experiment_id = get_or_create_experiment(model_class_name)\n",
    "\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "storage = optuna.storages.RDBStorage(url=f\"sqlite:///{model_class_name}.db\")\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout));\n",
    "study = optuna.create_study(study_name=study_name, storage=storage,load_if_exists=True,direction=\"maximize\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:58:40.222221Z",
     "start_time": "2023-11-23T16:58:39.808658Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "best_trial = study.best_trial\n",
    "print(f'Best trial: score {best_trial.value:.4f},\\nparams {best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:44:38.603611Z",
     "start_time": "2023-11-23T16:43:49.440045Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### Save , Load and Or train the best model further\n",
    "from machine_learning.IntentTokenizer import IntentTokenizer\n",
    "from machine_learning.IntentClassifierLSTMWithAttention import IntentClassifierLSTMWithAttention\n",
    "from machine_learning.model_utils import train, evaluate, predict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "train_df = pd.read_csv('data/atis/train.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "ood_df=pd.read_csv('data/atis/ood.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "train_df=pd.concat([train_df,ood_df])\n",
    "test_df = pd.read_csv('data/atis/test.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "\n",
    "tokenizer = IntentTokenizer(train_df,5000)\n",
    "\n",
    "train_data = tokenizer.process_data(train_df, device=device)\n",
    "test_data = tokenizer.process_data(test_df, device=device)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# define constants and hyperparameters\n",
    "num_epochs = 20\n",
    "model = IntentClassifierLSTMWithAttention(\n",
    "    vocab_size=len(tokenizer.word2idx)+1,\n",
    "    embedding_dim=best_trial.params['embedding_dim'],\n",
    "    hidden_dim=best_trial.params['hidden_dim'],\n",
    "    output_dim=len(tokenizer.le.classes_),\n",
    "    dropout_rate=best_trial.params['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_trial.params['lr'],\n",
    "                       weight_decay=best_trial.params['weight_decay'])\n",
    "train_loss = train(model, optimizer, nn.CrossEntropyLoss(), train_loader, num_epochs)\n",
    "test_accuracy = evaluate(model, nn.CrossEntropyLoss(), test_loader, data_type=\"Test\")\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Save the model\n",
    "Lets' use a clever construct to save the model. The model is saved with its class name. The parameters are saved in order in a json file. Later on this model can be recreated by providing the class name in the constructor and loading the parameters from the json file. The model state dictionary is saved in a separate file. The tokenizer and label encoder are also saved in separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:46:53.999700Z",
     "start_time": "2023-11-23T16:46:53.978686Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class_name=model.__class__.__name__\n",
    "print(f\"class_name={class_name}\")\n",
    "model.save_config_file(f\"config/{class_name}.json\")\n",
    "torch.save(model.state_dict(),f\"models/{class_name}_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load the model\n",
    "class_name is a string that can be used to create the model. The model state dictionary is loaded from the saved file. The tokenizer and label encoder are also loaded from the saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:52:53.746102Z",
     "start_time": "2023-11-23T16:52:52.334599Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the trained model and tokenizer from saved files\n",
    "from intent_classifier import IntentClassifier\n",
    "class_name=\"IntentClassifierLSTMWithAttention\"\n",
    "model_serve=IntentClassifier(class_name)\n",
    "model_serve.load(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:56:44.396277Z",
     "start_time": "2023-11-23T16:56:44.360321Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_str = \"how much do you charge for a flight to New York\"\n",
    "response = model_serve.predict(query_str)\n",
    "# Creating a DataFrame with the query string\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-23T16:57:00.471362Z",
     "start_time": "2023-11-23T16:57:00.428082Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "query_str = \"I want to book a hotel in New York\"\n",
    "response = model_serve.predict(query_str)\n",
    "# Creating a DataFrame with the query string\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Visualize the results\n",
    "Optuna provides a number of visualizations to analyze the results of the hyperparameter tuning experiment. I use these visualizations to analyze the results of the hyperparameter tuning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_contour(study)\n",
    "fig.update_layout(\n",
    "    width=1600,   # Width of the figure in pixels\n",
    "    height=800   # Height of the figure in pixels\n",
    ")\n",
    "fig.write_image(\"plotly_contours.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Plotly Contours](plotly_contours.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make very nice conclusions about embedding dimensions and hidden dimmesions along with other dimensions and even restart the study from here. For \n",
    "1. Embedding dimension is ideal somewhere between 100 and 300\n",
    "2. Hidden dimension is ideal between 50 50 100\n",
    "3. learning rate between 0.001 and 0.0001.\n",
    "4. dropout rate between 0.3 to 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "fig.update_layout(\n",
    "    width=1600,   # Width of the figure in pixels\n",
    "    height=800   # Height of the figure in pixels\n",
    ")\n",
    "fig.write_image(\"plot_parallel_coordinate.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parallel Coordinates](plot_parallel_coordinate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check Optuna's complete set of visualizations do the following:\n",
    "\n",
    "!pip install optuna-dashboard\n",
    "\n",
    "!optuna-dashboard sqlite:///IntentClassifierLSTMWithAttention.db "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Save the model and check model Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"best_ICELSTMAmodel\"\n",
    "torch.save(model, f\"models/{model_name}.pth\")\n",
    "tokenizer.save_state(f\"models/{model_name}_tokenizer.pickle\", f\"models/{model_name}_le.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load the trained model and tokenizer from saved files\n",
    "model_serve = torch.load(f\"models/{model_name}.pth\").to(device)\n",
    "tokenizer = IntentTokenizer.load_state(IntentTokenizer,f\"models/{model_name}_tokenizer.pickle\", f\"models/{model_name}_le.pickle\")\n",
    "max_query_length = 50\n",
    "query_text = \"what airlines off from love field between 6 and 10 am on june sixth\"\n",
    "query = pd.DataFrame({\"text\": [query_text]})\n",
    "prediction = predict(model_serve, query,tokenizer,device)\n",
    "print(f\"Predicted label: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step for model improvements\n",
    "\n",
    "Visualize the impact of Attentions and Embeddings\n",
    "One can visualize how attention and embeddings are playing but in the interest of time, I will not much further into improvment of training mechanism. I will shift to model evaulation and performance monitoring in production mode in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultimate_nlpv2",
   "language": "python",
   "name": "ultimate-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
