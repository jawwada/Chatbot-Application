{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534ec710-e8e4-4a43-887e-593d4ebe20d1",
   "metadata": {},
   "source": [
    "# Intent Classification Model on Atis Data using \n",
    "I plan to build a series of models. \n",
    "1. barebone model for Bench Marking\n",
    "2. Attention based model for trying deep architecture\n",
    "3. Using advance learning libraries to check how the performance of the two compare\n",
    "\n",
    "\n",
    "First importies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe401331",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:33.302413Z",
     "start_time": "2023-11-21T02:34:31.919382Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648bd5dd-1f83-4e3e-bee6-ef3e5e80fe62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:33.318041Z",
     "start_time": "2023-11-21T02:34:33.314872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\"\"\"\n",
    "    torch.manual_seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea481a-c956-48af-821b-91787297d0f5",
   "metadata": {},
   "source": [
    "# Barebone NLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df3ec35-6c92-4847-9e3a-753e9c798557",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "The process of getting a language agnostic representation of text is called tokenization. In this section, we will tokenize the text and build a vocabulary. We will also encode the labels as numerical values. This will help build an intent classifier model that an be used for chatbots in any domain and language\n",
    "### Tokenize and Build Vocabulary\n",
    "\n",
    "### Get the Indexed and Padded Sequences as Tensors\n",
    "\n",
    "### Encode Labels\n",
    "Also handle unknown labels, print a list of classes in the data\n",
    "\n",
    "### Text to Index Lists\n",
    "The text_to_indices function takes a string of text and the word_to_index dictionary.\n",
    "It tokenizes the text into words (using the tokenize function we assumed earlier).\n",
    "For each word in the tokenized text, it finds the corresponding index from the word_to_index dictionary. If the word is not found, it uses the index for \"<UNK>\".\n",
    "The function returns a list of indices representing the text.\n",
    "Finally, we use list comprehensions to apply this function to all entries in the training and testing datasets.\n",
    "After executing this code, train_indices and test_indices will be lists of lists, where each inner list is a sequence of word indices corresponding to a sentence in your training and testing datasets, respectively. These are now ready to be padded and then used for training your PyTorch model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ffda9ad-ae5e-4ef9-93bb-400f7ae1e52c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:34.505804Z",
     "start_time": "2023-11-21T02:34:33.320106Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 890\n",
      "Padded Training Sequences: torch.Size([4634, 46])\n",
      "Padded Testing Sequences: torch.Size([850, 30])\n",
      "Label Encoding: {'abbreviation': 0, 'aircraft': 1, 'aircraft+flight+flight_no': 2, 'airfare': 3, 'airfare+flight_time': 4, 'airline': 5, 'airline+flight_no': 6, 'airport': 7, 'capacity': 8, 'cheapest': 9, 'city': 10, 'distance': 11, 'flight': 12, 'flight+airfare': 13, 'flight_no': 14, 'flight_time': 15, 'ground_fare': 16, 'ground_service': 17, 'ground_service+ground_fare': 18, 'meal': 19, 'quantity': 20, 'restriction': 21, '<unknown>': 22}\n"
     ]
    }
   ],
   "source": [
    "from utils import tokenize, build_vocabulary, text_to_indices, encode_labels, convert_and_pad_sequences\n",
    "\n",
    "# Load the training data\n",
    "train = pd.read_csv(\"data/atis/train.tsv\",sep='\\t', header=None)\n",
    "train.columns = [\"text\", \"label\"]\n",
    "test= pd.read_csv(\"data/atis/test.tsv\",sep='\\t', header=None)\n",
    "test.columns = [\"text\", \"label\"]\n",
    "\n",
    "#build vocabulary\n",
    "vocab_size=1000\n",
    "word_to_index = build_vocabulary(train[\"text\"], vocab_size)\n",
    "print(f\"Vocabulary Size: {len(word_to_index)}\")\n",
    "\n",
    "#get the indexed and padded sequences as tensors\n",
    "train_indices = [text_to_indices(text, word_to_index) for text in train[\"text\"]]\n",
    "test_indices = [text_to_indices(text, word_to_index) for text in test[\"text\"]]\n",
    "train_padded=convert_and_pad_sequences(train_indices,device)\n",
    "test_padded=convert_and_pad_sequences(test_indices,device)\n",
    "# Now, train_padded and test_padded are the padded sequence tensors\n",
    "print(\"Padded Training Sequences:\", train_padded.size())\n",
    "print(\"Padded Testing Sequences:\", test_padded.size())\n",
    "\n",
    "# Convert labels to numerical values\n",
    "le = encode_labels(train,test)\n",
    "train_labels = le.transform(train[\"label\"])\n",
    "test_labels = le.transform(test[\"label\"])\n",
    "print(\"Label Encoding:\", dict(zip(le.classes_, le.transform(le.classes_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27009727-45eb-4986-b003-870298739477",
   "metadata": {},
   "source": [
    "Label Encoding: {'abbreviation': 0, 'aircraft': 1, 'aircraft+flight+flight_no': 2, 'airfare': 3, 'airfare+flight_time': 4, 'airline': 5, 'airline+flight_no': 6, 'airport': 7, 'capacity': 8, 'cheapest': 9, 'city': 10, 'distance': 11, 'flight': 12, 'flight+airfare': 13, 'flight_no': 14, 'flight_time': 15, 'ground_fare': 16, 'ground_service': 17, 'ground_service+ground_fare': 18, 'meal': 19, 'quantity': 20, 'restriction': 21, \"<unknown>\": 22}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb4f71",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11809b4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb87f36-d2ab-460c-bffe-00ba2b4fbd86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:34.510159Z",
     "start_time": "2023-11-21T02:34:34.508076Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3595324939.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[6], line 6\u001B[0;36m\u001B[0m\n\u001B[0;31m    |\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Create TensorDatasets\n",
    "# TensorDataset combines a dataset and a label, and provides an iterable over the given dataset. The arguments should be tensors of the same size in the 0th dimension. Any other dimension will be considered as the sample dimension and will be iterated along. This dataset is especially useful to wrap tensors that represent input and target or that are already in batches, e.g. for mini-batch SGD.\n",
    "train_data = TensorDataset(train_padded.to(device), torch.tensor(train_labels).to(device))\n",
    "test_data = TensorDataset(test_padded.to(device), torch.tensor(test_labels).to(device))\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "print(\"Number of training batches:\", len(train_loader))\n",
    "print(\"Number of test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e1b1f73-a8f8-45fe-bb66-80de1266e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_padded.cpu().numpy()).to_csv('train_tensor1.csv')\n",
    "pd.DataFrame(test_padded.cpu().numpy()).to_csv('test_tensor1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "878f8cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:34.903353Z",
     "start_time": "2023-11-21T02:34:34.892709Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "(x,y)= train_data.tensors\n",
    "pd.DataFrame(y.cpu().numpy()).to_csv('train_tensor_y2.csv')\n",
    "(x,y)= test_data.tensors\n",
    "pd.DataFrame(y.cpu().numpy()).to_csv('test_tensor_y2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c849b-3dc0-4dcd-862a-3ad69682047e",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Yay, our data is now vectorized. We can start playing with it. The first step is to build an embedding model. In this code:\n",
    "\n",
    "vocab_size is the number of unique words in your vocabulary.\n",
    "embedding_dim is the number of dimensions for each word embedding.\n",
    "SimpleNLPModel is a basic PyTorch model class with an embedding layer.\n",
    "The forward method defines how data passes through the model. In this simple example, it only passes through the embedding layer.\n",
    "Finally, an example input is passed through the model to obtain embeddings. The input should be a tensor of token indices, like the output of your padding step.\n",
    "This setup will initialize the embeddings randomly, and they will be updated during training. If you have pre-trained embeddings that you want to use, you can initialize the nn.Embedding layer with these pre-trained weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb73f06-014a-4a44-9355-cf0ff793b0a0",
   "metadata": {},
   "source": [
    "Great!. The Embeddings are working. , if we want to use advance embeddings, we can also use pretrained embeddings, including contextualized embeddings from the task. Lets refine our Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9958c25f-ca17-4f7c-91a7-4099c5d841a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:41.628433Z",
     "start_time": "2023-11-21T02:34:38.899831Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahmedjawad/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/ahmedjawad/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class IntentClassifierLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(IntentClassifierLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)  # Batch normalization layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(x)\n",
    "\n",
    "        # Dropout layer\n",
    "        dropped = self.dropout1(embedded)\n",
    "\n",
    "        # LSTM layer\n",
    "        lstm_out, (hidden, _) = self.lstm(dropped)\n",
    "        # Take the output of the last time step\n",
    "        hidden = hidden[-1]\n",
    "        # Batch normalization\n",
    "        normalized = self.batch_norm(hidden)\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.fc(normalized)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model with dropout and batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee5e703-a7f5-49b4-8cd3-8de90e57c983",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:41.643824Z",
     "start_time": "2023-11-21T02:34:41.633417Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttentionLayer(nn.Module):\n",
    "    def __init__(self, feature_size):\n",
    "        super(SelfAttentionLayer, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "\n",
    "        # Linear transformations for Q, K, V from the same source\n",
    "        self.key = nn.Linear(feature_size, feature_size)\n",
    "        self.query = nn.Linear(feature_size, feature_size)\n",
    "        self.value = nn.Linear(feature_size, feature_size)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Apply linear transformations\n",
    "        keys = self.key(x)\n",
    "        queries = self.query(x)\n",
    "        values = self.value(x)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(queries, keys.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.feature_size, dtype=torch.float32))\n",
    "\n",
    "        # Apply mask (if provided)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # Apply softmax\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Multiply weights with values\n",
    "        output = torch.matmul(attention_weights, values)\n",
    "\n",
    "        return output\n",
    "class IntentClassifierLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate):\n",
    "        super(IntentClassifierLSTMWithAttention, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.attention = SelfAttentionLayer(hidden_dim)\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        dropped = self.dropout(embedded)\n",
    "        lstm_out, _ = self.lstm(dropped)\n",
    "\n",
    "        # Apply attention\n",
    "        attn_out = self.attention(lstm_out)\n",
    "        final_output= attn_out[:, -1, :]\n",
    "        normalized = self.batch_norm(final_output)\n",
    "\n",
    "        out = self.fc(normalized)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af8efc5-d23a-46fe-acdf-eb4f7087d0f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:41.644291Z",
     "start_time": "2023-11-21T02:34:41.636748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Size: 1000\n",
      "Embedding Dim: 64\n",
      "Hidden Dim: 128\n",
      "Output Dim: 23\n",
      "Dropout Rate: 0.4\n",
      "learning Rate: 0.001\n",
      "epochs: 20\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate=0.001\n",
    "weight_decay=1e-4\n",
    "dropout_rate=0.4\n",
    "embedding_dim =64            # Size of each embedding vector\n",
    "hidden_dim = 128               # Number of features in the hidden state of the LSTM\n",
    "batch_size = 32\n",
    "output_dim = len(le.classes_)  # Number of classes\n",
    "num_epochs=20\n",
    "# Create a string that summarizes these parameters\n",
    "params_str = f\"Vocab Size: {vocab_size}\\n\" \\\n",
    "             f\"Embedding Dim: {embedding_dim}\\n\" \\\n",
    "             f\"Hidden Dim: {hidden_dim}\\n\" \\\n",
    "             f\"Output Dim: {output_dim}\\n\" \\\n",
    "             f\"Dropout Rate: {dropout_rate}\\n\" \\\n",
    "             f\"learning Rate: {learning_rate}\\n\" \\\n",
    "             f\"epochs: {num_epochs}\"\n",
    "print(params_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd27564",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training and Evaluation\n",
    "Implement a training loop for the model. You can use any optimizer and loss function of your choice. You can also use any other metric that you think is suitable for the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2e71e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:34:42.644576Z",
     "start_time": "2023-11-21T02:34:42.639088Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "device=\"mps\"\n",
    "print(torch.backends.mps.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f5a36b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:37:08.084518Z",
     "start_time": "2023-11-21T02:36:27.306232Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.6267\n",
      "Epoch [1/20], Accuracy: 0.6826\n",
      "Epoch [2/20], Loss: 0.5782\n",
      "Epoch [2/20], Accuracy: 0.8753\n",
      "Epoch [3/20], Loss: 0.3465\n",
      "Epoch [3/20], Accuracy: 0.9137\n",
      "Epoch [4/20], Loss: 0.2728\n",
      "Epoch [4/20], Accuracy: 0.9318\n",
      "Epoch [5/20], Loss: 0.2188\n",
      "Epoch [5/20], Accuracy: 0.9441\n",
      "Epoch [6/20], Loss: 0.1869\n",
      "Epoch [6/20], Accuracy: 0.9530\n",
      "Epoch [7/20], Loss: 0.1535\n",
      "Epoch [7/20], Accuracy: 0.9579\n",
      "Epoch [8/20], Loss: 0.1272\n",
      "Epoch [8/20], Accuracy: 0.9681\n",
      "Epoch [9/20], Loss: 0.1178\n",
      "Epoch [9/20], Accuracy: 0.9683\n",
      "Epoch [10/20], Loss: 0.1046\n",
      "Epoch [10/20], Accuracy: 0.9709\n",
      "Epoch [11/20], Loss: 0.0851\n",
      "Epoch [11/20], Accuracy: 0.9767\n",
      "Epoch [12/20], Loss: 0.0888\n",
      "Epoch [12/20], Accuracy: 0.9767\n",
      "Epoch [13/20], Loss: 0.0727\n",
      "Epoch [13/20], Accuracy: 0.9769\n",
      "Epoch [14/20], Loss: 0.0673\n",
      "Epoch [14/20], Accuracy: 0.9806\n",
      "Epoch [15/20], Loss: 0.0630\n",
      "Epoch [15/20], Accuracy: 0.9834\n",
      "Epoch [16/20], Loss: 0.0594\n",
      "Epoch [16/20], Accuracy: 0.9827\n",
      "Epoch [17/20], Loss: 0.0475\n",
      "Epoch [17/20], Accuracy: 0.9862\n",
      "Epoch [18/20], Loss: 0.0469\n",
      "Epoch [18/20], Accuracy: 0.9871\n",
      "Epoch [19/20], Loss: 0.0416\n",
      "Epoch [19/20], Accuracy: 0.9899\n",
      "Epoch [20/20], Loss: 0.0562\n",
      "Epoch [20/20], Accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "#model = IntentClassifierLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "model = IntentClassifierLSTMWithAttention(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0.0\n",
    "    correct=0.0\n",
    "    acc=0\n",
    "    for batch in train_loader:\n",
    "        # get data\n",
    "        x, y = batch\n",
    "        # zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        y_hat = model(x)\n",
    "        # compute loss\n",
    "        loss = loss_function(y_hat, y)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # step\n",
    "        optimizer.step()\n",
    "        # update train loss\n",
    "        # compute accuracy\n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        correct += (predicted == y).sum().item()\n",
    "    # compute average losses\n",
    "    train_loss /= len(train_loader)\n",
    "    acc=(correct/len(train_padded))\n",
    "\n",
    "    # log average losses\n",
    "    mlflow.log_metric(\"train_loss\", train_loss, step=epoch)\n",
    "    # Log training loss per epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}')\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "521bdb41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:37:16.367608Z",
     "start_time": "2023-11-21T02:37:14.259113Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3297\n",
      "Test Accuracy: 0.9624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlflow.models.model.ModelInfo at 0x2ce2d6610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# evaluate on test set\n",
    "test_loss = 0.0\n",
    "correct=0\n",
    "acc=0\n",
    "for batch in test_loader:\n",
    "    # get data\n",
    "    x, y = batch\n",
    "    # forward pass\n",
    "    y_hat = model(x)\n",
    "    # compute loss\n",
    "    loss = loss_function(y_hat, y)\n",
    "    # update test loss\n",
    "    test_loss += loss.item()\n",
    "    _, predicted = torch.max(y_hat, 1)\n",
    "    correct += (predicted == y).sum().item()\n",
    "# compute average losses\n",
    "test_loss /= len(test_loader)\n",
    "acc=(correct/len(test_padded))\n",
    "\n",
    "# log average losses\n",
    "mlflow.log_metric(\"test_loss\", test_loss, step=epoch)\n",
    "mlflow.log_metric(\"test_accuracy\", acc, step=epoch)\n",
    "# Log the precision and recall\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# log model\n",
    "mlflow.pytorch.log_model(model, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67a3193f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:36:12.804884Z",
     "start_time": "2023-11-21T02:35:41.253009Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12, 12, 15,  ...,  5, 12, 12], device='mps:0')\n",
      "Epoch [1/20], Loss: 0.0520\n",
      "Epoch [1/20], Accuracy: 0.6798\n",
      "Epoch [2/20], Loss: 0.0185\n",
      "Epoch [2/20], Accuracy: 0.8748\n",
      "Epoch [3/20], Loss: 0.0113\n",
      "Epoch [3/20], Accuracy: 0.9132\n",
      "Epoch [4/20], Loss: 0.0087\n",
      "Epoch [4/20], Accuracy: 0.9348\n",
      "Epoch [5/20], Loss: 0.0064\n",
      "Epoch [5/20], Accuracy: 0.9486\n",
      "Epoch [6/20], Loss: 0.0054\n",
      "Epoch [6/20], Accuracy: 0.9545\n",
      "Epoch [7/20], Loss: 0.0045\n",
      "Epoch [7/20], Accuracy: 0.9590\n",
      "Epoch [8/20], Loss: 0.0040\n",
      "Epoch [8/20], Accuracy: 0.9685\n",
      "Epoch [9/20], Loss: 0.0036\n",
      "Epoch [9/20], Accuracy: 0.9704\n",
      "Epoch [10/20], Loss: 0.0031\n",
      "Epoch [10/20], Accuracy: 0.9722\n",
      "Epoch [11/20], Loss: 0.0027\n",
      "Epoch [11/20], Accuracy: 0.9771\n",
      "Epoch [12/20], Loss: 0.0023\n",
      "Epoch [12/20], Accuracy: 0.9769\n",
      "Epoch [13/20], Loss: 0.0026\n",
      "Epoch [13/20], Accuracy: 0.9767\n",
      "Epoch [14/20], Loss: 0.0022\n",
      "Epoch [14/20], Accuracy: 0.9801\n",
      "Epoch [15/20], Loss: 0.0016\n",
      "Epoch [15/20], Accuracy: 0.9840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 47\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[38;5;66;03m# Backward pass and optimize\u001B[39;00m\n\u001B[1;32m     46\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 47\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m _, predicted \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(outputs, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     49\u001B[0m correct \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (predicted \u001B[38;5;241m==\u001B[39m label_batch)\u001B[38;5;241m.\u001B[39msum()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:68\u001B[0m, in \u001B[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     66\u001B[0m instance\u001B[38;5;241m.\u001B[39m_step_count \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     67\u001B[0m wrapped \u001B[38;5;241m=\u001B[39m func\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__get__\u001B[39m(instance, \u001B[38;5;28mcls\u001B[39m)\n\u001B[0;32m---> 68\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:373\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    368\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    369\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    370\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    371\u001B[0m             )\n\u001B[0;32m--> 373\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/torch/optim/optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/torch/optim/adam.py:163\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    152\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    155\u001B[0m         group,\n\u001B[1;32m    156\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    160\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    161\u001B[0m         state_steps)\n\u001B[0;32m--> 163\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    165\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    166\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    167\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    168\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    169\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    170\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    171\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    173\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    174\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    175\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/torch/optim/adam.py:311\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    309\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 311\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    323\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    324\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    325\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    326\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    327\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Job Search/Ultimate AI Challenge/ultimate_ai/venv/lib/python3.9/site-packages/torch/optim/adam.py:385\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[1;32m    384\u001B[0m exp_avg\u001B[38;5;241m.\u001B[39mlerp_(grad, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m beta1)\n\u001B[0;32m--> 385\u001B[0m \u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddcmul_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconj\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m capturable \u001B[38;5;129;01mor\u001B[39;00m differentiable:\n\u001B[1;32m    388\u001B[0m     step \u001B[38;5;241m=\u001B[39m step_t\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    mlflow.end_run()\n",
    "except:\n",
    "    pass\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "#model = IntentClassifierLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "model = IntentClassifierLSTMWithAttention(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Convert labels to torch tensor\n",
    "train_labels_tensor = torch.tensor(train_labels).to(device)\n",
    "test_labels_tensor = torch.tensor(test_labels).to(device)\n",
    "print(train_labels_tensor)\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter()\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifacts(writer.log_dir, artifact_path=\"tensorboard_logs\")\n",
    "\n",
    "    # Log model architecture\n",
    "    mlflow.log_text(str(model), \"model.txt\")\n",
    "\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_text(params_str, \"model_parameters.txt\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss=0\n",
    "        correct=0\n",
    "        accuracy=0\n",
    "        for i in range(0, len(train_padded), batch_size):\n",
    "            # Batch inputs and labels\n",
    "            input_batch = train_padded[i:i+batch_size].to(device)\n",
    "            label_batch = train_labels_tensor[i:i+batch_size]\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_function(outputs, label_batch)\n",
    "            train_loss+=loss.item()\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == label_batch).sum().item()\n",
    "        avg_loss=train_loss/len(train_padded)\n",
    "        accuracy=(correct/len(train_padded))\n",
    "        # Log training loss per epoch\n",
    "        mlflow.log_metric(\"train_loss\",avg_loss , step=epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')\n",
    "        if accuracy>0.995:\n",
    "            break\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    correct=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_padded), batch_size):\n",
    "            # Batch inputs and labels\n",
    "            input_batch = test_padded[i:i+batch_size]\n",
    "            label_batch = test_labels_tensor[i:i+batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == label_batch).sum().item()\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, label_batch)\n",
    "            total_loss += loss.item()\n",
    "            #total_loss += loss.item() * input_batch.size(0)\n",
    "\n",
    "\n",
    "    # Compute and log the average test loss\n",
    "    average_loss = total_loss / len(test_padded)\n",
    "    print(f\"Test Loss: {average_loss:.4f}\")\n",
    "    accuracy = (correct / len(test_padded))\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    mlflow.log_metric(\"test_loss\", average_loss)\n",
    "    mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "    writer.add_scalar(\"Loss/test\", average_loss)\n",
    "\n",
    "    # Log the final model to MLflow\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f57a31-f615-4295-a536-4f002f30d454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "#model = IntentClassifierLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "model = IntentClassifierLSTMWithAttention(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate,weight_decay=weight_decay)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Convert labels to torch tensor\n",
    "train_labels_tensor = torch.tensor(train_labels).to(device)\n",
    "test_labels_tensor = torch.tensor(test_labels).to(device)\n",
    "print(train_labels_tensor)\n",
    "# TensorBoard writer\n",
    "writer = SummaryWriter()\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_artifacts(writer.log_dir, artifact_path=\"tensorboard_logs\")\n",
    "\n",
    "    # Log model architecture\n",
    "    mlflow.log_text(str(model), \"model.txt\")\n",
    "    \n",
    "    # Log hyperparameters\n",
    "    mlflow.log_text(params_str, \"model_parameters.txt\")\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss=0\n",
    "        correct=0\n",
    "        accuracy=0\n",
    "        for i in range(0, len(train_padded), batch_size):\n",
    "            # Batch inputs and labels\n",
    "            input_batch = train_padded[i:i+batch_size].to(device)\n",
    "            label_batch = train_labels_tensor[i:i+batch_size]\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_batch)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = loss_function(outputs, label_batch)\n",
    "            train_loss+=loss.item()\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == label_batch).sum().item()\n",
    "        avg_loss=train_loss/len(train_padded)\n",
    "        accuracy=(correct/len(train_padded))\n",
    "        # Log training loss per epoch\n",
    "        mlflow.log_metric(\"train_loss\",avg_loss , step=epoch)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')\n",
    "        if accuracy>0.998:\n",
    "            break\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    correct=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(test_padded), batch_size):\n",
    "            # Batch inputs and labels\n",
    "            input_batch = test_padded[i:i+batch_size]\n",
    "            label_batch = test_labels_tensor[i:i+batch_size]\n",
    "    \n",
    "            # Forward pass\n",
    "            outputs = model(input_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == label_batch).sum().item()\n",
    "            # Compute loss\n",
    "            loss = loss_function(outputs, label_batch)\n",
    "            total_loss += loss.item()\n",
    "            #total_loss += loss.item() * input_batch.size(0)\n",
    "      \n",
    "\n",
    "    # Compute and log the average test loss\n",
    "    average_loss = total_loss / len(test_padded)\n",
    "    print(f\"Test Loss: {average_loss:.4f}\")\n",
    "    accuracy = (correct / len(test_padded))\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    mlflow.log_metric(\"test_loss\", average_loss)\n",
    "    writer.add_scalar(\"Loss/test\", average_loss)\n",
    "\n",
    "    # Log the final model to MLflow\n",
    "    mlflow.pytorch.log_model(model, \"model\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c2d483f-80b5-44a2-8f6c-e3f4169f37d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:37:35.823573Z",
     "start_time": "2023-11-21T02:37:35.719218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight+airfare, Actual: flight+airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: <unknown>\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: <unknown>\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: meal, Actual: meal\n",
      "Predicted: meal, Actual: meal\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight_time, Actual: flight_time\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: city, Actual: city\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: airfare, Actual: ground_fare\n",
      "Predicted: airfare, Actual: ground_fare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: quantity, Actual: quantity\n",
      "Predicted: quantity, Actual: quantity\n",
      "Predicted: quantity, Actual: quantity\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: city, Actual: airport\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: meal, Actual: meal\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: ground_fare, Actual: ground_fare\n",
      "Predicted: ground_fare, Actual: ground_fare\n",
      "Predicted: ground_fare, Actual: ground_fare\n",
      "Predicted: airfare, Actual: ground_fare\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: capacity, Actual: aircraft\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight+airfare, Actual: flight+airfare\n",
      "Predicted: flight+airfare, Actual: flight+airfare\n",
      "Predicted: flight+airfare, Actual: flight+airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight+airfare\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: <unknown>\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: ground_service, Actual: ground_fare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: meal, Actual: meal\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: aircraft, Actual: aircraft\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight+airfare\n",
      "Predicted: airfare, Actual: flight+airfare\n",
      "Predicted: flight, Actual: flight+airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: <unknown>\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight+airfare\n",
      "Predicted: flight, Actual: flight+airfare\n",
      "Predicted: flight_no, Actual: <unknown>\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: flight, Actual: airport\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: aircraft, Actual: aircraft\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight+airfare, Actual: flight+airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: distance, Actual: distance\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: airport, Actual: city\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: aircraft, Actual: aircraft\n",
      "Predicted: flight+airfare, Actual: flight+airfare\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: capacity\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight+airfare, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: flight_no, Actual: flight_no\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: quantity, Actual: flight\n",
      "Predicted: quantity, Actual: flight\n",
      "Predicted: quantity, Actual: flight\n",
      "Predicted: city, Actual: city\n",
      "Predicted: city, Actual: city\n",
      "Predicted: city, Actual: city\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: aircraft, Actual: aircraft\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: meal, Actual: meal\n",
      "Predicted: flight, Actual: meal\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: aircraft, Actual: aircraft\n",
      "Predicted: aircraft, Actual: aircraft\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: capacity, Actual: capacity\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: abbreviation, Actual: abbreviation\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: quantity, Actual: flight\n",
      "Predicted: airline, Actual: flight\n",
      "Predicted: airline, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airfare, Actual: airfare\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: aircraft, Actual: aircraft\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: ground_service, Actual: ground_service\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airline, Actual: airline\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: airport, Actual: airport\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n",
      "Predicted: flight, Actual: flight\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(0, len(test_padded), batch_size):\n",
    "        # Batch inputs and labels\n",
    "        input_batch = test_padded[i:i+batch_size].to(device)\n",
    "        label_batch = test_labels_tensor[i:i+batch_size].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        # Convert predictions and labels to CPU and then to NumPy\n",
    "        predicted_np = predicted.cpu().numpy()\n",
    "        labels_np = label_batch.cpu().numpy()\n",
    "\n",
    "        # Convert numerical labels to original categorical labels\n",
    "        predicted_labels = le.inverse_transform(predicted_np)\n",
    "        actual_labels = le.inverse_transform(labels_np)\n",
    "\n",
    "        # Print predicted and actual labels side by side\n",
    "        for pred, actual in zip(predicted_labels, actual_labels):\n",
    "            print(f\"Predicted: {pred}, Actual: {actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0134ba01-9415-4e6a-a524-2e1e1d4ac724",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:37:49.448139Z",
     "start_time": "2023-11-21T02:37:49.442239Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')\n",
    "#model_serve=IntentClassifierLSTMWithAttention(cfg.vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "#model_serve.load_state_dict(torch.load('model_state_dict.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de3ccd1f-03f0-43ea-b23c-390b9bbba0ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T02:37:55.878326Z",
     "start_time": "2023-11-21T02:37:55.151694Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 28, 791, 2, 247, 248, 31, 148, 17, 151, 86, 5, 150, 295], [0, 0]]\n",
      "[tensor([  6,  28, 791,   2, 247, 248,  31, 148,  17, 151,  86,   5, 150, 295],\n",
      "       device='mps:0'), tensor([0, 0], device='mps:0')]\n",
      "tensor([[  6,  28, 791,   2, 247, 248,  31, 148,  17, 151,  86,   5, 150, 295],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
      "       device='mps:0')\n",
      "Predicted label: ['flight' 'abbreviation']\n"
     ]
    }
   ],
   "source": [
    "model_serve = torch.load('model.pth')\n",
    "\n",
    "def predict(model, query, max_length):\n",
    "    model.eval()\n",
    "    # Tokenize and prepare input\n",
    "    query_indices = [text_to_indices(text, word_to_index) for text in query]\n",
    "    print(query_indices)\n",
    "    query_tensor = [torch.tensor(seq).to(device) for seq in query_indices]\n",
    "    print(query_tensor)\n",
    "    input = pad_sequence(query_tensor, batch_first=True, padding_value=0)\n",
    "    print(input)\n",
    "    # Inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    # Convert prediction to label\n",
    "    return le.inverse_transform(predicted.data.cpu().numpy())\n",
    "torch.save(model.state_dict(), 'model_state_dict.pth')\n",
    "\n",
    "\n",
    "\n",
    "query=list()\n",
    "query.append(\"what airlines off from love field between 6 and 10 am on june sixth\")\n",
    "query.append(\"unknown sequence\")\n",
    "prediction = predict(model_serve, query,46)\n",
    "print(f\"Predicted label: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda57e3d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultimate_nlp",
   "language": "python",
   "name": "ultimate-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
