{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51fd1e24",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Third Party Models. Abstraction of Tokenization and Intent Classifier \n",
    "\n",
    "#### This notebook has two parts. \n",
    "1. using Hugging Face Transformer\n",
    "2. Demonstarion of a Transformer like Interface for Models (Own Tokenizer and Model Abstraction), with train, eval and predict functions that can be used to trained any model.\n",
    "\n",
    "## 4.1 Transformer, Bert's Intent Classification\n",
    "I trained and fine tuned a language model with Attention Mechanism previously. However, I have not made it generalized. Let's use Hugging face transformers. \n",
    "An example Intent Classification model using BERT and HuggingFace Transformers.\n",
    "Steps:\n",
    "1. Load data\n",
    "2. Tokenize data\n",
    "3. Create PyTorch Dataset\n",
    "4. Train model\n",
    "5. Evaluate model\n",
    "6. Save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ba54bca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T23:25:23.003867Z",
     "start_time": "2023-11-21T23:25:18.629779Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abbreviation' 'aircraft' 'aircraft+flight+flight_no' 'airfare'\n",
      " 'airfare+flight_time' 'airline' 'airline+flight_no' 'airport' 'capacity'\n",
      " 'cheapest' 'city' 'distance' 'flight' 'flight+airfare' 'flight_no'\n",
      " 'flight_time' 'ground_fare' 'ground_service' 'ground_service+ground_fare'\n",
      " 'meal' 'quantity' 'restriction' '<unknown>']\n",
      "23\n",
      "Vocabulary size: 890\n",
      "Index of the word 'flight': 32\n",
      "[99, 100, 140, 15, 141, 142, 12, 97]\n",
      "[1, 93, 86, 3, 4, 5, 28, 64, 3, 68, 23, 260, 265]\n",
      "mps\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import config_bert as cfg\n",
    "import warnings\n",
    "from transformers import TrainerCallback\n",
    "from machine_learning.model_utils import get_or_create_experiment\n",
    "from machine_learning.IntentTokenizer import IntentTokenizer\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585bd028",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    " ## Data Loading\n",
    " I will use the pretrained Bert tokenizer. The tokenizer will convert the text into tokens that the model can understand. The model will be trained to classify the intent of the text. I will use the BertForSequenceClassification model, which is a pretrained Bert model with a single linear classification layer on top. This model can be used for sequence classification tasks like ours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c74f208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T23:25:24.884345Z",
     "start_time": "2023-11-21T23:25:23.005060Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the pre-trained model for sequence classification with the number of labels\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(cfg.le.classes_))\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6eb0f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## PyTorch Dataset\n",
    "The data set uses encodings from tokenizer and labels from label encoder. The data set is then used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6705cecf-4482-45fa-90b0-3d40b639a6ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T23:25:25.762342Z",
     "start_time": "2023-11-21T23:25:24.945933Z"
    }
   },
   "outputs": [],
   "source": [
    "class IntentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('data/atis/train.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "test_df = pd.read_csv('data/atis/test.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "\n",
    "# Assume the second column is the label and the first column is the text\n",
    "train_texts = train_df[\"text\"].tolist()\n",
    "test_texts = test_df[\"text\"].tolist()\n",
    "\n",
    "# Convert labels to integer (if they are not already)\n",
    "# This might involve using a LabelEncoder as you have categorical labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = cfg.le\n",
    "num_labels = len(cfg.le.classes_)\n",
    "\n",
    "# Tokenize the text and create datasets\n",
    "max_length = 256  # Max length of the text sequence, you might need to adjust this based on your dataset\n",
    "train_dataset = IntentDataset(train_texts, cfg.train_labels, tokenizer, max_length)\n",
    "test_dataset = IntentDataset(test_texts, cfg.test_labels, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe7174b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Training\n",
    "Hyperparameters are defined here. The model is trained and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "329965f9-8bad-46aa-b2f3-b1a3ac1630c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T23:29:58.967429Z",
     "start_time": "2023-11-21T23:25:25.766465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='501' max='870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [501/870 01:35 < 01:10, 5.21 it/s, Epoch 1.72/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.309900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.069300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.481200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.373800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.173100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Run with id=350825cd37c14ca2b3ebd945656b8fc6 not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestException\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#mlflow.log_params(your_params_dict)  # Log any initial parameters\u001b[39;00m\n\u001b[1;32m     38\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     39\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     40\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[MLflowLoggingCallback()]\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mend_run()\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/transformers/trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/transformers/trainer.py:1922\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1922\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/transformers/trainer.py:2257\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step\n\u001b[1;32m   2255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_flos()\n\u001b[0;32m-> 2257\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2259\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/transformers/trainer.py:2645\u001b[0m, in \u001b[0;36mTrainer.log\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2643\u001b[0m output \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlogs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step}}\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mlog_history\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[0;32m-> 2645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallback_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_log\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/transformers/trainer_callback.py:400\u001b[0m, in \u001b[0;36mCallbackHandler.on_log\u001b[0;34m(self, args, state, control, logs)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_log\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl, logs):\n\u001b[1;32m    399\u001b[0m     control\u001b[38;5;241m.\u001b[39mshould_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_event\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_log\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/transformers/trainer_callback.py:407\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_event\u001b[39m(\u001b[38;5;28mself\u001b[39m, event, args, state, control, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 407\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m            \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;66;03m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/transformers/integrations/integration_utils.py:1035\u001b[0m, in \u001b[0;36mMLflowCallback.on_log\u001b[0;34m(self, args, state, control, logs, model, **kwargs)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1031\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1032\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrainer is attempting to log a value of \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(v)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for key \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as a metric. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1033\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLflow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms log_metric() only accepts float and int types so we dropped this attribute.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1034\u001b[0m         )\n\u001b[0;32m-> 1035\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ml_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/fluent.py:816\u001b[0m, in \u001b[0;36mlog_metrics\u001b[0;34m(metrics, step, synchronous)\u001b[0m\n\u001b[1;32m    814\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m get_current_time_millis()\n\u001b[1;32m    815\u001b[0m metrics_arr \u001b[38;5;241m=\u001b[39m [Metric(key, value, timestamp, step \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m--> 816\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/client.py:1086\u001b[0m, in \u001b[0;36mMlflowClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_batch\u001b[39m(\n\u001b[1;32m   1018\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1019\u001b[0m     run_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1023\u001b[0m     synchronous: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[RunOperations]:\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;124;03m    Log multiple metrics, params, and/or tags.\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m        status: FINISHED\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1086\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:459\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metrics_batch \u001b[38;5;129;01min\u001b[39;00m chunk_list(metrics, chunk_size\u001b[38;5;241m=\u001b[39mMAX_METRICS_PER_BATCH):\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n\u001b[0;32m--> 459\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m         run_operations_list\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    462\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mlog_batch_async(\n\u001b[1;32m    463\u001b[0m                 run_id\u001b[38;5;241m=\u001b[39mrun_id, metrics\u001b[38;5;241m=\u001b[39mmetrics_batch, params\u001b[38;5;241m=\u001b[39m[], tags\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m    464\u001b[0m             )\n\u001b[1;32m    465\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:323\u001b[0m, in \u001b[0;36mRestStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m    319\u001b[0m tag_protos \u001b[38;5;241m=\u001b[39m [tag\u001b[38;5;241m.\u001b[39mto_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags]\n\u001b[1;32m    320\u001b[0m req_body \u001b[38;5;241m=\u001b[39m message_to_json(\n\u001b[1;32m    321\u001b[0m     LogBatch(metrics\u001b[38;5;241m=\u001b[39mmetric_protos, params\u001b[38;5;241m=\u001b[39mparam_protos, tags\u001b[38;5;241m=\u001b[39mtag_protos, run_id\u001b[38;5;241m=\u001b[39mrun_id)\n\u001b[1;32m    322\u001b[0m )\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLogBatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/store/tracking/rest_store.py:59\u001b[0m, in \u001b[0;36mRestStore._call_endpoint\u001b[0;34m(self, api, json_body)\u001b[0m\n\u001b[1;32m     57\u001b[0m endpoint, method \u001b[38;5;241m=\u001b[39m _METHOD_TO_INFO[api]\n\u001b[1;32m     58\u001b[0m response_proto \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mResponse()\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:210\u001b[0m, in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    208\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m json_body\n\u001b[1;32m    209\u001b[0m     response \u001b[38;5;241m=\u001b[39m http_request(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs)\n\u001b[0;32m--> 210\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m js_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m    212\u001b[0m parse_dict(js_dict\u001b[38;5;241m=\u001b[39mjs_dict, message\u001b[38;5;241m=\u001b[39mresponse_proto)\n",
      "File \u001b[0;32m~/miniforge3/envs/py3910/lib/python3.9/site-packages/mlflow/utils/rest_utils.py:142\u001b[0m, in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response\u001b[38;5;241m.\u001b[39mtext):\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext))\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m         base_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != 200\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         )\n",
      "\u001b[0;31mRestException\u001b[0m: RESOURCE_DOES_NOT_EXIST: Run with id=350825cd37c14ca2b3ebd945656b8fc6 not found"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=1e-5,               # strength of weight decay\n",
    "    logging_dir='./logs',  \n",
    "    logging_strategy=\"steps\",  # or \"epoch\"\n",
    "    logging_steps=50,  # Log every 10 steps# directory for storing logs,\n",
    "    save_strategy=\"no\"\n",
    ")\n",
    "\n",
    "class MLflowLoggingCallback(TrainerCallback):\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        # Log metrics with MLflow here\n",
    "        if metrics:\n",
    "            for key, value in metrics.items():\n",
    "                mlflow.log_metric(key, value, step=state.global_step)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:1234/\")\n",
    "try:\n",
    "    # Create an experiment and log parameters\n",
    "    mlflow(pytorch=True)\n",
    "    mlflow.start_run()\n",
    "    mlflow.log_param(\"epochs\", training_args.num_train_epochs)\n",
    "    mlflow.log_param(\"batch_size\", training_args.per_device_train_batch_size)\n",
    "    mlflow.log_param(\"learning_rate\", training_args.learning_rate)\n",
    "    mlflow.log_param(\"weight_decay\", training_args.weight_decay)\n",
    "    mlflow.log_param(\"warmup_steps\", training_args.warmup_steps)\n",
    "    mlflow.log_param(\"max_length\", max_length)\n",
    "    mlflow.log_param(\"num_labels\", num_labels)\n",
    "    mlflow.log_param(\"model\", \"bert-base-uncased\")\n",
    "\n",
    "except:\n",
    "    pass\n",
    "#mlflow.log_params(your_params_dict)  # Log any initial parameters\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    callbacks=[MLflowLoggingCallback()]\n",
    ")\n",
    "trainer.train()\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2facb0df",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9cecb1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.save_model('bert-results/final_bert_evaluated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ea53d2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    " ## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1afde02-e977-4abd-8203-dc873dbe788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83612db-b574-429c-9e79-6e86289c48c8",
   "metadata": {},
   "source": [
    "# 4.2 Implementaion of Abstraction ELSTM+Attention\n",
    "Hugging face has its own tokenizer and training interface that abstracts pytorch implementation. I implement a similar approach. I provide an intercae that encapsulates pytorch and just exposes the parameters. Classes are implemented in machine_learning directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a563561-1604-4bd0-a45a-2e4d8e521676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from machine_learning.IntentTokenizer import IntentTokenizer\n",
    "from machine_learning.IntentClassifierLSTMWithAttention import IntentClassifierLSTMWithAttention\n",
    "from machine_learning.model_utils import train, evaluate, predict\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load and preprocess the data\n",
    "train_df = pd.read_csv('data/atis/train.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])\n",
    "test_df = pd.read_csv('data/atis/test.tsv', sep='\\t', header=None, names=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e57b0e-2bcf-4f28-842d-71b833b5a1ba",
   "metadata": {},
   "source": [
    "### Own Tokenizer Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9fa6a0-342b-4747-a2f1-b3e0b821deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = IntentTokenizer(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777fff00-ec4f-4208-8893-7ce6f0dad133",
   "metadata": {},
   "source": [
    "### Get data Tensors and Loaders in One go\n",
    "\n",
    "I use a Tupled Tensor Data Set, (two Tensors) first one giving the sequences, and and the 2nd one the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8331cd3e-861f-4575-95df-0944c07ed696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "train_data = tokenizer.process_data(train_df,device=device)\n",
    "test_data = tokenizer.process_data(test_df,device=device)\n",
    "print(\"Number of training samples:\", train_data.tensors[0].size())\n",
    "print(\"Number of test samples:\", test_data.tensors[0].size())\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "print(\"Number of training batches:\", len(train_loader))\n",
    "print(\"Number of test batches:\", len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c693f5-3869-4512-9156-ad44fa88b471",
   "metadata": {},
   "source": [
    "### Encode Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00421fd7-9909-4da8-86d4-d6dbca069d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.005              # If you set this too high, it might explode. If too low, it might not learn\n",
    "weight_decay = 1e-7               # Regularization strength\n",
    "dropout_rate = 0.3                 # Dropout rate\n",
    "embedding_dim = 128                # Size of each embedding vector\n",
    "hidden_dim = 256                 # Number of features in the hidden state of the LSTM\n",
    "batch_size = 32                  # Number of samples in each batch\n",
    "output_dim = len(IntentTokenizer.le.classes_)  # Number of classes\n",
    "num_epochs = 5         # Number of times to go through the entire dataset\n",
    "vocab_size = tokenizer.max_vocab_size + 1  # The size of the vocabulary\n",
    "# Create a string that summarizes these parameters\n",
    "params_str = f\"Vocab Size: {vocab_size}\\n\" \\\n",
    "             f\"Embedding Dim: {embedding_dim}\\n\" \\\n",
    "             f\"Hidden Dim: {hidden_dim}\\n\" \\\n",
    "             f\"Output Dim: {output_dim}\\n\" \\\n",
    "             f\"Dropout Rate: {dropout_rate}\\n\" \\\n",
    "             f\"learning Rate: {learning_rate}\\n\" \\\n",
    "             f\"epochs: {num_epochs}\"\n",
    "print(params_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c1bac-04be-4871-aa67-9c3fdf87617e",
   "metadata": {},
   "source": [
    "### Train, Evaluate, and Predict Abstraction\n",
    "with 3,4 lines of code, you can almost train, evaluate any intent classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d2d0cb-8ac2-49fb-92fa-73ae346bff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the model and train it. Evaluate the model on the test set.\n",
    "# choose model to train, uncomment the model you want to train and comment the other one\n",
    "# IntentClassifierLSTM is a simple LSTM model. IntentClassifierLSTMWithAttention is a LSTM model with attention.\n",
    "# The latter performs better.\n",
    "# Difference in Accuracy between the two models is about 3%\n",
    "\n",
    "# model = IntentClassifierLSTM(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "model = IntentClassifierLSTMWithAttention(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train(model, optimizer, loss_function, train_loader, num_epochs)\n",
    "evaluate(model, loss_function, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade7b12-6d50-4752-8424-d4a9d6b4733d",
   "metadata": {},
   "source": [
    "### Model and Tokenization Saving\n",
    "A clever way to save the file can help us later , when building a flask server to give the class name and loading the model dynamically. I show how to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606f57c-9b43-4da0-9383-1e32030c0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name=model.__class__.__name__\n",
    "print(class_name)\n",
    "print(f\"class_name={class_name}\")\n",
    "model.save_config_file(f\"config/{class_name}.json\")\n",
    "torch.save(model.state_dict(),f\"models/{class_name}_state_dict.pth\")\n",
    "tokenizer.save_state(f\"models/{class_name}_tokenizer.pickle\", f\"models/{class_name}_le.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a566999-aea9-4027-85cc-96e3bd507f46",
   "metadata": {},
   "source": [
    "## Now load the model dynamically, we will pass the same name ot IntentClassifier class, which will load the parameters of the modela and state dict from config and model dirs on run time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b946f191-fb57-4dc4-8de3-0a9cbe19683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model and tokenizer from saved files\n",
    "from intent_classifier import IntentClassifier\n",
    "class_name=\"IntentClassifierLSTMWithAttention\"\n",
    "model_serve=IntentClassifier(class_name)\n",
    "model_serve.load(class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138d87b-98d5-42ea-a6cb-f8c9fdb6b3ce",
   "metadata": {},
   "source": [
    "### Model Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756d7fa-efef-4d2f-b386-2f572ae9dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a query\n",
    "max_query_length = 50\n",
    "query_text = \"what airlines off from love field between 6 and 10 am on june sixth\"\n",
    "\n",
    "prediction = model_serve.predict(query_text)\n",
    "print(f\"Predicted label: {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e4134-62e3-436e-88c4-811a0f4eca6c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In the Notebooks, I have accomplished the following:\n",
    "1. Show how to train a simple model and add Attention Mechanism to improve accuracy\n",
    "2. Building a better model through cross validation based hyper parameter selection and parameter logging.\n",
    "3. Model Management, Registry, and Experiment Management. Very important parts of MLOPs and Machine Learning Engineering\n",
    "4. Model Evaluation, on test data and performance during production time. Confidence Scores and Performance Improvment by using a distillation approach (using gpt4 to create OOS data and fine tune the best model choosen through hyperparameter selection). Improve production accuracy and performance\n",
    "5. Using Hugging Face Pretrained Transformers model. Fine tuning on Atis Data Set\n",
    "6. Building a Transfomer like Abstract Interface to ELSTM with Attention Model, i.e. Hide Pytorch and Only allow parameters to pass through (code in machine_learning folder)\n",
    "\n",
    "I hope many of the questions in the challenge are resolved. There are tons of things one can do there, one can visualize the impact of Attentions and Embeddings, one can implement A/B testing, logging in production, discuss more distillation approaches, etc.. looking forward to more fun :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34938274-d9e6-47a1-a69e-8056406ff2b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
