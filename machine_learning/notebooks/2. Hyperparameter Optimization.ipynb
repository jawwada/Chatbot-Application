{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#    Hyperparameter Tuning for Intent Classification using LSTM with Attention Mechanism\n",
    "This notebook is 2nd part of the Ultimate AI Challenge. In the previous notebook, I trained a LSTM Model with Attention Mechanism for Intent Classification on the ATIS dataset. In this notebook, I perform a hyper parameter optimization to learn the best parameters for the model and also log our experiments using an ML server, e.g. MLFlow. Propreitary clouds already use experiment logging, model registry and deployment services, e.g. Vertex AI in GCP, Azure ML and Amazon Sagemaker. I have worked in Vertex AI and Azure ML. MLflow + Optuna is a good open source and scalable alternative to them. I use Optuna for hyperparameter tuning and MLflow for experiment tracking and model registry. Model Serving is done through pytorch save and load methods. To avoid pickling and version issues, one can also use model state dictionaries. The notebook is divided into the following sections:\n",
    "1. Data Preparation\n",
    "2. Hyperparameter Tuning\n",
    "3. Model Training and Evaluation\n",
    "4. Visualize the results\n",
    "5. Model Export, Registry, Model Loading and Inference\n",
    "\n",
    "Let's start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note; carefully set the project Root, so relative class imports work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:14:12.891866Z",
     "start_time": "2023-11-25T00:14:12.759533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/ahmedjawad/Documents/JobSearch/UltimateAIChallenge/ultimate_aiv2\n"
     ]
    }
   ],
   "source": [
    "# if your notebook starts in the current directory, you need to set the directory to project root\n",
    "import os\n",
    "marker = '.git'  # Replace with your unique marker file or directory\n",
    "while not os.path.exists(marker):\n",
    "    os.chdir('..')\n",
    "# Verify the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-25T00:14:15.518007Z",
     "start_time": "2023-11-25T00:14:12.764058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside IntentTokenizer\n",
      "Actual Vocabulary Size: 890\n",
      "Encoding labels for the first time and adding unknown class.\n",
      "Label Encoding: {'abbreviation': 0, 'aircraft': 1, 'aircraft+flight+flight_no': 2, 'airfare': 3, 'airfare+flight_time': 4, 'airline': 5, 'airline+flight_no': 6, 'airport': 7, 'capacity': 8, 'cheapest': 9, 'city': 10, 'distance': 11, 'flight': 12, 'flight+airfare': 13, 'flight_no': 14, 'flight_time': 15, 'ground_fare': 16, 'ground_service': 17, 'ground_service+ground_fare': 18, 'meal': 19, 'quantity': 20, 'restriction': 21, '<unknown>': 22}\n",
      "Using device: mps\n",
      "Number of training samples: torch.Size([4634, 46])\n",
      "Number of training batches: 145\n",
      "Number of test samples: torch.Size([850, 30])\n",
      "Number of test batches: 27\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import mlflow\n",
    "from machine_learning.pipelines.data_loaders import vocab_size, output_dim, batch_size, device\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Data Preparation\n",
    "Steps:\n",
    "1. Load the data\n",
    "2. Tokenize the data\n",
    "3. Create a PyTorch Dataset\n",
    "4. Create a PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:14:15.523969Z",
     "start_time": "2023-11-25T00:14:15.519277Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Hyperparameter Tuning\n",
    "The Model I am using for the hyperparameter tuning is the IntentClassifierLSTMWithAttention. The hyperparameters are:\n",
    "1. Learning rate : 1e-3 to 1e-1\n",
    "2. Hidden dimension : 32, 64, 128, 256\n",
    "3. Embedding dimension : 64, 128, 256, 512\n",
    "4. Dropout rate : 0.1 to 0.5\n",
    "5. Weight decay : 1e-6 to 1e-3\n",
    "\n",
    "The objective function is the average validation accuracy over 5 folds. The best model is the one with the highest average validation accuracy. Note our test data is completely hidden to the accuracy optimizer of optuna. One can choose any metric to optimize, for example minimization of loss, etc.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Optuna Study for Hyperparameter Optimization\n",
    "Create an experiment in MLflow and run the hyperparameter tuning experiment. The best model is the one with the highest average validation accuracy. You can install the mlflow and optuna using pip install. To start mlflow server, I used the following command\n",
    "`mlflow server --backend-store-uri=sqlite:///mlrunsdb15.db --default-artifact-root=file:mlruns --host 127.0.0.1 --port 1234`\n",
    "Once started, it creates mlruns directory in project root and also a db in the root to log the progress, store models and experiments. In practise, it is installed on a server, and http requests are sent to the server. Anyhow pay close attention to the directory you give in the command to run the server. Here I keep it simple. Optuna also creates a db to store it's studies. Here I choose 20 tries. For 5 folds cross validation, and 5 epochs each, the study takes less than an hour my M1 machine. Optuna uses Bayesian Parameter Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the MLflow Server\n",
    "\n",
    "pip install mlflow\n",
    "\n",
    "`mlflow server --backend-store-uri=mlruns --default-artifact-root=file:mlruns --host 127.0.0.1 --port 1234`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "### How to define the objective function"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T00:14:15.524199Z",
     "start_time": "2023-11-25T00:14:15.522255Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def log_hyperparameters(trial):\n",
    "    # Log hyperparameters\n",
    "\n",
    "    mlflow.log_param(\"lr\", trial.params[\"lr\"])\n",
    "    mlflow.log_param(\"hidden_dim\", trial.params[\"hidden_dim\"])\n",
    "    mlflow.log_param(\"embedding_dim\", trial.params[\"embedding_dim\"])\n",
    "    mlflow.log_param(\"dropout_rate\", trial.params[\"dropout_rate\"])\n",
    "    mlflow.log_param(\"weight_decay\", trial.params[\"weight_decay\"])\n",
    "    print(\n",
    "        f'lr: {trial.params[\"lr\"]}, hidden_dim: {trial.params[\"hidden_dim\"]}, embedding_dim: {trial.params[\"embedding_dim\"]}, dropout_rate: {trial.params[\"dropout_rate\"]}, weight_decay: {trial.params[\"weight_decay\"]}')\n",
    "\n",
    "    return True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T00:14:15.528239Z",
     "start_time": "2023-11-25T00:14:15.526622Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def objective_ELSTMA(trial):\n",
    "    from machine_learning.learners.IntentClassifierLSTMWithAttention import IntentClassifierLSTMWithAttention\n",
    "    from sklearn.model_selection import KFold\n",
    "    from machine_learning.pipelines.data_loaders import train_df, test_loader, tokenizer\n",
    "    from machine_learning.learners.model_utils import train, evaluate\n",
    "    epochs = 3\n",
    "    with mlflow.start_run():\n",
    "        # Suggest hyperparameters\n",
    "        lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "        hidden_dim = trial.suggest_categorical(\"hidden_dim\", [32, 64, 256])\n",
    "        embedding_dim = trial.suggest_categorical(\"embedding_dim\", [64, 128, 256])\n",
    "        dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        log_hyperparameters(trial)\n",
    "        # Model, loss, and optimizer\n",
    "        # model = IntentClassifierLSTM(cfg.vocab_size, embedding_dim, hidden_dim, cfg.output_dim,dropout_rate).to(device)\n",
    "        model = IntentClassifierLSTMWithAttention(vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold_val_acc = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kfold.split(train_df)):\n",
    "            # Prepare fold data\n",
    "            train_data_subset = tokenizer.process_data(train_df.loc[train_idx,:], device=device)\n",
    "            val_data_subset = tokenizer.process_data(train_df.loc[val_idx,:], device=device)\n",
    "            train_subset_loader = DataLoader(train_data_subset, batch_size=batch_size, shuffle=True)\n",
    "            val_subset_loader = DataLoader(val_data_subset, batch_size=batch_size, shuffle=False)\n",
    "            fold_loss = train(model, optimizer, criterion, train_subset_loader, epochs)\n",
    "            val_accuracy = evaluate(model,  criterion, val_subset_loader, data_type=\"Validation\")\n",
    "            print(f'Fold: {fold + 1}, Training Loss: {fold_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "            fold_val_acc.append(val_accuracy)\n",
    "        average_val_acc = sum(fold_val_acc) / len(fold_val_acc)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"train_loss\", fold_loss)\n",
    "        print(f'Foldloss: {fold_loss:.4f}')\n",
    "        mlflow.log_metric(\"accuracy\", average_val_acc)\n",
    "        print(f'Average validation accuracy: {average_val_acc:.4f}')\n",
    "        test_accuracy = evaluate(model, nn.CrossEntropyLoss(), test_loader, data_type=\"Test\")\n",
    "        print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "        mlflow.pytorch.log_model(model, f\"best_model_{study.study_name}\")\n",
    "        if test_accuracy>0.97:\n",
    "            mlflow.pytorch.log_model(model, f\"best_model_{study.study_name}_test_accuracy_{test_accuracy}\")\n",
    "    return average_val_acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T00:14:15.534370Z",
     "start_time": "2023-11-25T00:14:15.533108Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-11-25T00:16:43.327669Z",
     "start_time": "2023-11-25T00:14:42.020617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.002953811327086381, hidden_dim: 64, embedding_dim: 128, dropout_rate: 0.3284367520175706, weight_decay: 2.4930518646037698e-05\n",
      "Epoch [1/3], Loss: 1.0852, Accuracy: 0.7896\n",
      "Test Loss: 0.5672\n",
      "Test Accuracy: 0.8835\n",
      "Epoch [2/3], Loss: 0.3616, Accuracy: 0.9274\n",
      "Test Loss: 0.4296\n",
      "Test Accuracy: 0.9071\n",
      "Epoch [3/3], Loss: 0.1755, Accuracy: 0.9601\n",
      "Test Loss: 0.3695\n",
      "Test Accuracy: 0.9318\n",
      "Validation Loss: 0.1034\n",
      "Validation Accuracy: 0.9720\n",
      "Fold: 1, Training Loss: 0.1755, Validation Accuracy: 0.9720\n",
      "Epoch [1/3], Loss: 0.1325, Accuracy: 0.9690\n",
      "Test Loss: 0.2747\n",
      "Test Accuracy: 0.9341\n",
      "Epoch [2/3], Loss: 0.0914, Accuracy: 0.9752\n",
      "Test Loss: 0.2964\n",
      "Test Accuracy: 0.9306\n",
      "Epoch [3/3], Loss: 0.0744, Accuracy: 0.9808\n",
      "Test Loss: 0.3573\n",
      "Test Accuracy: 0.9459\n",
      "Validation Loss: 0.1369\n",
      "Validation Accuracy: 0.9784\n",
      "Fold: 2, Training Loss: 0.0744, Validation Accuracy: 0.9784\n",
      "Epoch [1/3], Loss: 0.0855, Accuracy: 0.9798\n",
      "Test Loss: 0.2142\n",
      "Test Accuracy: 0.9541\n",
      "Epoch [2/3], Loss: 0.0546, Accuracy: 0.9876\n",
      "Test Loss: 0.2505\n",
      "Test Accuracy: 0.9635\n",
      "Epoch [3/3], Loss: 0.0500, Accuracy: 0.9852\n",
      "Test Loss: 0.3190\n",
      "Test Accuracy: 0.9482\n",
      "Validation Loss: 0.0226\n",
      "Validation Accuracy: 0.9924\n",
      "Fold: 3, Training Loss: 0.0500, Validation Accuracy: 0.9924\n",
      "Epoch [1/3], Loss: 0.0494, Accuracy: 0.9865\n",
      "Test Loss: 0.3130\n",
      "Test Accuracy: 0.9588\n",
      "Epoch [2/3], Loss: 0.0518, Accuracy: 0.9876\n",
      "Test Loss: 0.3397\n",
      "Test Accuracy: 0.9565\n",
      "Epoch [3/3], Loss: 0.0306, Accuracy: 0.9911\n",
      "Test Loss: 0.3480\n",
      "Test Accuracy: 0.9541\n",
      "Early stopping\n",
      "Validation Loss: 0.0389\n",
      "Validation Accuracy: 0.9914\n",
      "Fold: 4, Training Loss: 0.0306, Validation Accuracy: 0.9914\n",
      "Epoch [1/3], Loss: 0.0316, Accuracy: 0.9916\n",
      "Test Loss: 0.3907\n",
      "Test Accuracy: 0.9494\n",
      "Epoch [2/3], Loss: 0.0282, Accuracy: 0.9914\n",
      "Test Loss: 0.4253\n",
      "Test Accuracy: 0.9565\n",
      "Epoch [3/3], Loss: 0.0338, Accuracy: 0.9900\n",
      "Test Loss: 0.3832\n",
      "Test Accuracy: 0.9588\n",
      "Early stopping\n",
      "Validation Loss: 0.0107\n",
      "Validation Accuracy: 0.9968\n",
      "Fold: 5, Training Loss: 0.0338, Validation Accuracy: 0.9968\n",
      "Foldloss: 0.0338\n",
      "Average validation accuracy: 0.9862\n",
      "Test Loss: 0.4096\n",
      "Test Accuracy: 0.9588\n",
      "Test Accuracy: 0.9588\n",
      "lr: 0.001116980057505453, hidden_dim: 256, embedding_dim: 128, dropout_rate: 0.3884483794110311, weight_decay: 1.028033931816843e-05\n",
      "Epoch [1/3], Loss: 1.3206, Accuracy: 0.7448\n",
      "Test Loss: 0.5971\n",
      "Test Accuracy: 0.8753\n",
      "Epoch [2/3], Loss: 0.4303, Accuracy: 0.9072\n",
      "Test Loss: 0.5399\n",
      "Test Accuracy: 0.9059\n",
      "Epoch [3/3], Loss: 0.2784, Accuracy: 0.9390\n",
      "Test Loss: 0.3703\n",
      "Test Accuracy: 0.9329\n",
      "Validation Loss: 0.1218\n",
      "Validation Accuracy: 0.9687\n",
      "Fold: 1, Training Loss: 0.2784, Validation Accuracy: 0.9687\n",
      "Epoch [1/3], Loss: 0.2127, Accuracy: 0.9509\n",
      "Test Loss: 0.4129\n",
      "Test Accuracy: 0.9388\n",
      "Epoch [2/3], Loss: 0.1637, Accuracy: 0.9633\n",
      "Test Loss: 0.3995\n",
      "Test Accuracy: 0.9388\n",
      "Epoch [3/3], Loss: 0.1363, Accuracy: 0.9692\n",
      "Test Loss: 0.3984\n",
      "Test Accuracy: 0.9235\n",
      "Validation Loss: 0.1779\n",
      "Validation Accuracy: 0.9471\n",
      "Fold: 2, Training Loss: 0.1363, Validation Accuracy: 0.9471\n",
      "Epoch [1/3], Loss: 0.1347, Accuracy: 0.9706\n",
      "Test Loss: 0.3202\n",
      "Test Accuracy: 0.9529\n",
      "Epoch [2/3], Loss: 0.0945, Accuracy: 0.9744\n",
      "Test Loss: 0.3650\n",
      "Test Accuracy: 0.9518\n",
      "Epoch [3/3], Loss: 0.0874, Accuracy: 0.9741\n",
      "Test Loss: 0.3191\n",
      "Test Accuracy: 0.9553\n",
      "Validation Loss: 0.0684\n",
      "Validation Accuracy: 0.9860\n",
      "Fold: 3, Training Loss: 0.0874, Validation Accuracy: 0.9860\n",
      "Epoch [1/3], Loss: 0.0940, Accuracy: 0.9738\n",
      "Test Loss: 0.3144\n",
      "Test Accuracy: 0.9447\n",
      "Epoch [2/3], Loss: 0.0683, Accuracy: 0.9811\n",
      "Test Loss: 0.3250\n",
      "Test Accuracy: 0.9565\n",
      "Epoch [3/3], Loss: 0.0485, Accuracy: 0.9868\n",
      "Test Loss: 0.3018\n",
      "Test Accuracy: 0.9659\n",
      "Validation Loss: 0.0115\n",
      "Validation Accuracy: 0.9968\n",
      "Fold: 4, Training Loss: 0.0485, Validation Accuracy: 0.9968\n",
      "Epoch [1/3], Loss: 0.0657, Accuracy: 0.9844\n",
      "Test Loss: 0.3045\n",
      "Test Accuracy: 0.9588\n",
      "Epoch [2/3], Loss: 0.0513, Accuracy: 0.9868\n",
      "Test Loss: 0.2958\n",
      "Test Accuracy: 0.9624\n",
      "Epoch [3/3], Loss: 0.0393, Accuracy: 0.9873\n",
      "Test Loss: 0.2657\n",
      "Test Accuracy: 0.9706\n",
      "Validation Loss: 0.0196\n",
      "Validation Accuracy: 0.9946\n",
      "Fold: 5, Training Loss: 0.0393, Validation Accuracy: 0.9946\n",
      "Foldloss: 0.0393\n",
      "Average validation accuracy: 0.9786\n",
      "Test Loss: 0.2557\n",
      "Test Accuracy: 0.9706\n",
      "Test Accuracy: 0.9706\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:1234')\n",
    "\n",
    "model_class_name = \"IntentClassifierLSTMWithAttention\"\n",
    "#optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "storage_name = \"sqlite:///data/db/{}.db\".format(model_class_name)\n",
    "study = optuna.create_study(study_name=model_class_name, load_if_exists=True, storage=storage_name,direction=\"maximize\")\n",
    "study.optimize(objective_ELSTMA, n_trials=2)\n",
    "best_trial = study.best_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Best Model Training and Evaluation (Saving, Reloading the best model, through optuna or mlflow)\n",
    "Once I find the best set of hyper parameters, you can open mlflow on tracking uri, e.g. in my case , I set http://127.0.0.1:1234. Also if you install optuna-dashboard, you can see very nice visualizations and get very detailed insights on hyperparameter space, their importance, and why some combinations work more than others. I invite to try it. Tune the best model with a larger number of epochs and evaluate it on the test set. You can reload an optuna study from its' db later to get the best parameters and train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Train the best model\n",
    "Let's say that you have saved an optuna study and you want to reload it later. You feel that the number of epochs were not enough and you want to train the best model with more epochs. Or you want save the model initialization parameters so that you can load the model initial state later and use it along with the saved state dictionary. You can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:16:43.335695Z",
     "start_time": "2023-11-25T00:16:43.329402Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import logging\n",
    "import sys\n",
    "# Reload Optuna Study to get the best parameters\n",
    "model_class_name = \"IntentClassifierLSTMWithAttention\"\n",
    "#experiment_id = get_or_create_experiment(model_class_name)\n",
    "if experiment := mlflow.get_experiment_by_name(model_class_name):\n",
    "    experiment_id= experiment.experiment_id\n",
    "else:\n",
    "    experiment_id=mlflow.create_experiment(model_class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "storage_name = \"sqlite:///data/db/{}.db\".format(model_class_name)\n",
    "study = optuna.create_study(study_name=model_class_name, load_if_exists=True, storage=storage_name,direction=\"maximize\")\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "storage = optuna.storages.RDBStorage(url=f\"sqlite:///data/db/{model_class_name}.db\")\n",
    "optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout));\n",
    "study = optuna.create_study(study_name=model_class_name, storage=storage,load_if_exists=True,direction=\"maximize\");"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-25T00:16:43.375687Z",
     "start_time": "2023-11-25T00:16:43.337721Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:16:43.387604Z",
     "start_time": "2023-11-25T00:16:43.377627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: score 0.9903,\n",
      "params {'lr': 0.0013487934809448435, 'hidden_dim': 64, 'embedding_dim': 128, 'dropout_rate': 0.17918187700846566, 'weight_decay': 4.75333827188117e-05}\n"
     ]
    }
   ],
   "source": [
    "best_trial = study.best_trial\n",
    "print(f'Best trial: score {best_trial.value:.4f},\\nparams {best_trial.params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:24.868850Z",
     "start_time": "2023-11-25T00:16:43.389755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.1125, Accuracy: 0.7943\n",
      "Test Loss: 0.6413\n",
      "Test Accuracy: 0.8835\n",
      "Epoch [2/15], Loss: 0.3232, Accuracy: 0.9344\n",
      "Test Loss: 0.6764\n",
      "Test Accuracy: 0.9106\n",
      "Epoch [3/15], Loss: 0.1815, Accuracy: 0.9603\n",
      "Test Loss: 0.3442\n",
      "Test Accuracy: 0.9400\n",
      "Epoch [4/15], Loss: 0.1244, Accuracy: 0.9722\n",
      "Test Loss: 0.3034\n",
      "Test Accuracy: 0.9482\n",
      "Epoch [5/15], Loss: 0.0868, Accuracy: 0.9791\n",
      "Test Loss: 0.3000\n",
      "Test Accuracy: 0.9518\n",
      "Epoch [6/15], Loss: 0.0682, Accuracy: 0.9827\n",
      "Test Loss: 0.3063\n",
      "Test Accuracy: 0.9565\n",
      "Epoch [7/15], Loss: 0.0700, Accuracy: 0.9842\n",
      "Test Loss: 0.3326\n",
      "Test Accuracy: 0.9576\n",
      "Epoch [8/15], Loss: 0.0535, Accuracy: 0.9862\n",
      "Test Loss: 0.4206\n",
      "Test Accuracy: 0.9600\n",
      "Epoch [9/15], Loss: 0.0600, Accuracy: 0.9864\n",
      "Test Loss: 0.3738\n",
      "Test Accuracy: 0.9576\n",
      "Epoch [10/15], Loss: 0.0520, Accuracy: 0.9875\n",
      "Test Loss: 0.3775\n",
      "Test Accuracy: 0.9553\n",
      "Epoch [11/15], Loss: 0.0249, Accuracy: 0.9937\n",
      "Test Loss: 0.2841\n",
      "Test Accuracy: 0.9647\n",
      "Early stopping\n",
      "Test Loss: 0.2852\n",
      "Test Accuracy: 0.9647\n",
      "Test Accuracy: 0.9647\n"
     ]
    }
   ],
   "source": [
    "from machine_learning.learners.IntentClassifierLSTMWithAttention import IntentClassifierLSTMWithAttention\n",
    "from machine_learning.pipelines.data_loaders import train_loader, test_loader, tokenizer\n",
    "from machine_learning.learners.model_utils import train, evaluate\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # define constants and hyperparameters\n",
    "    num_epochs = 15\n",
    "    model = IntentClassifierLSTMWithAttention(\n",
    "        vocab_size=len(tokenizer.word2idx)+1,\n",
    "        embedding_dim=256,\n",
    "        hidden_dim=128,\n",
    "        output_dim=len(tokenizer.le.classes_),\n",
    "        dropout_rate=0.4\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0013,\n",
    "                           weight_decay=4.5e-06)\n",
    "    train_loss = train(model, optimizer, nn.CrossEntropyLoss(), train_loader, num_epochs)\n",
    "    test_accuracy = evaluate(model, nn.CrossEntropyLoss(), test_loader, data_type=\"Test\")\n",
    "    mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "    print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Save the model\n",
    "One can save the model in a number of ways. torch.save and torch.load are the most common ways, however this creates a pickle file and can cause python version issues. Saving the model state dictionary and loading it later is a better way. Because it can be mapped to any model class and device. For quick notebook saving and loading I use torch.save and torch.load. For production, I use model state dictionary and provide a clever construct to save the model. The model is saved with its class name. The parameters are saved in order in a json file. Later on this model can be recreated by providing the class name in the constructor and loading the parameters from the json file. The model state dictionary is saved in a separate file. The tokenizer and label encoder are also saved in separate files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:24.880123Z",
     "start_time": "2023-11-25T00:17:24.870403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_name=IntentClassifierLSTMWithAttention\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class_name=model.__class__.__name__\n",
    "print(f\"class_name={class_name}\")\n",
    "model.save_config_file(f\"config/model_initialization/{class_name}.json\")\n",
    "torch.save(model.state_dict(),f\"data/models/{class_name}_state_dict.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Load the model\n",
    "class_name is a string that can be used to create the model. The model state dictionary is loaded from the saved file. The tokenizer and label encoder are also loaded from the saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:24.902145Z",
     "start_time": "2023-11-25T00:17:24.881260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model and tokenizer from saved files\n",
    "from machine_learning.learners.intent_classifier import IntentClassifier\n",
    "class_name=\"IntentClassifierLSTMWithAttention\"\n",
    "model_serve=IntentClassifier(class_name)\n",
    "model_serve.load(class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:24.971170Z",
     "start_time": "2023-11-25T00:17:24.901856Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'airfare', 'confidence': 0.9917524456977844}, {'label': 'abbreviation', 'confidence': 0.0018157875165343285}, {'label': 'ground_fare', 'confidence': 0.0017492893384769559}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_str = \"how much do you charge for a flight to New York\"\n",
    "response = model_serve.predict(query_str)\n",
    "# Creating a DataFrame with the query string\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:25.008552Z",
     "start_time": "2023-11-25T00:17:24.971955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'flight', 'confidence': 0.9957910776138306}, {'label': 'flight_time', 'confidence': 0.0013819440500810742}, {'label': 'airport', 'confidence': 0.0005671249236911535}]\n"
     ]
    }
   ],
   "source": [
    "query_str = \"I want to book a hotel in New York\"\n",
    "response = model_serve.predict(query_str)\n",
    "# Creating a DataFrame with the query string\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Visualize the results\n",
    "Optuna provides a number of visualizations to analyze the results of the hyperparameter tuning experiment. I use these visualizations to analyze the results of the hyperparameter tuning experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:26.407415Z",
     "start_time": "2023-11-25T00:17:25.009745Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_contour(study)\n",
    "fig.update_layout(\n",
    "    width=1600,   # Width of the figure in pixels\n",
    "    height=800   # Height of the figure in pixels\n",
    ")\n",
    "fig.write_image(\"machine_learning/notebooks/plotly_contours.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parallel Coordinates](plotly_contours.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make very nice conclusions about embedding dimensions and hidden dimmesions along with other dimensions and even restart the study from here. For \n",
    "1. Embedding dimension is ideal somewhere between 100 and 300\n",
    "2. Hidden dimension is ideal between 50 50 100\n",
    "3. learning rate between 0.001 and 0.0001.\n",
    "4. dropout rate between 0.3 to 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:28.628641Z",
     "start_time": "2023-11-25T00:17:26.412733Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "fig.update_layout(\n",
    "    width=1600,   # Width of the figure in pixels\n",
    "    height=800   # Height of the figure in pixels\n",
    ")\n",
    "fig.write_image(\"machine_learning/notebooks/plot_parallel_coordinate.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parallel Coordinates](plot_parallel_coordinate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check Optuna's complete set of visualizations do the following:\n",
    "\n",
    "!pip install optuna-dashboard\n",
    "\n",
    "!optuna-dashboard sqlite:///IntentClassifierLSTMWithAttention.db "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Save any model and tokenizer combination, and server from any model and tokenizer combination\n",
    "While building different models, there can be situations when a user is interested in saving any model_token combination and serving from it later. The following functions can be used to save and serve from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "ExecuteTime": {
     "end_time": "2023-11-25T00:17:28.691856Z",
     "start_time": "2023-11-25T00:17:28.629467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: ['airfare']\n"
     ]
    },
    {
     "data": {
      "text/plain": "array(['airfare'], dtype=object)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from machine_learning.learners.model_utils import save_modelname_tokenizer, serve_modelname_query\n",
    "model_name=\"best_ICELSTMAmodel\"\n",
    "save_modelname_tokenizer(model, \"Best_ELSTMA\", tokenizer)\n",
    "serve_modelname_query(model_name, \"how much do you charge for a flight to New York\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Step for model improvements\n",
    "\n",
    "Visualize the impact of Attentions and Embeddings\n",
    "One can visualize how attention and embeddings are playing but in the interest of time, I will not much further into improvment of training mechanism. I will shift to model evaulation and performance monitoring in production mode in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultimate_nlpv2",
   "language": "python",
   "name": "ultimate-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
